{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf9151e",
   "metadata": {},
   "source": [
    "# Sentiment Embeddings Model Evaluation\n",
    "\n",
    "This notebook loads the archived sentiment model and evaluates it on the test set. Metrics and visualizations are saved to the evaluation directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c25b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: imports and paths\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EVAL_DIR = Path('../evaluation/sentiment_embeddings').resolve()\n",
    "MODEL_DIR = Path('../../models/sentiment_embeddings/sentiment_distilbert_best/sentiment_distilbert/best').resolve()\n",
    "SPLITS_PATH = Path('../../outputs/sentiment_embeddings/preprocessing/splits.json').resolve()\n",
    "\n",
    "sys.path.insert(0, str(EVAL_DIR))\n",
    "from eval_utils import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c815b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test split and labels\n",
    "with open(SPLITS_PATH, 'r', encoding='utf-8') as f:\n",
    "    splits = json.load(f)\n",
    "labels = splits['labels']\n",
    "test_records = splits['splits']['test']\n",
    "\n",
    "test_df = pd.DataFrame([{'text': r['text'], 'label': labels.index(r['label'])} for r in test_records])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b9c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "model.eval()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6190d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for _, row in test_df.iterrows():\n",
    "        inputs = tokenizer(row['text'], return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "        logits = model(**inputs).logits.cpu().numpy()[0]\n",
    "        pred = np.argmax(logits)\n",
    "        all_preds.append(pred)\n",
    "        all_labels.append(row['label'])\n",
    "all_preds, all_labels = np.array(all_preds), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and save metrics\n",
    "metrics = compute_metrics(all_labels, all_preds, labels)\n",
    "with open(EVAL_DIR / 'metrics.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ebc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "cm = np.array(metrics['confusion_matrix'])\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "im = ax.imshow(cm, cmap='Blues')\n",
    "ax.set_xticks(np.arange(len(labels)))\n",
    "ax.set_yticks(np.arange(len(labels)))\n",
    "ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "ax.set_yticklabels(labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar(im)\n",
    "plt.tight_layout()\n",
    "plt.savefig(EVAL_DIR / 'confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5baf52",
   "metadata": {},
   "source": [
    "## Results\n",
    "- Metrics are saved to `metrics.json` in the evaluation directory.\n",
    "- Confusion matrix is saved as `confusion_matrix.png`.\n",
    "- See the classification report in the metrics output above."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
