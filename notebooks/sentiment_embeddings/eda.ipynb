{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858155d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mateusz/dev/pjatk_zum/.venv/lib64/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mateusz/dev/pjatk_zum/.venv/lib64/python3.14/site-packages/multiprocess/connection.py:335: SyntaxWarning: 'return' in a 'finally' block\n",
      "  return f\n",
      "/home/mateusz/dev/pjatk_zum/.venv/lib64/python3.14/site-packages/multiprocess/connection.py:337: SyntaxWarning: 'return' in a 'finally' block\n",
      "  return self._get_more_data(ov, maxsize)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from enum import StrEnum\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "import evaluate\n",
    "\n",
    "import pandas as pd\n",
    "from utils.paths import CACHE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b4279a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = CACHE_PATH / \"sentiment_embeddings\"\n",
    "raw_data_path = data_path / \"raw\" / \"aclImdb\"\n",
    "test_directory_path = raw_data_path / \"test\"\n",
    "train_directory_path = raw_data_path / \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44411ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(StrEnum):\n",
    "    POS = \"pos\"\n",
    "    NEG = \"neg\"\n",
    "\n",
    "def _load_data(sentiment: Sentiment, dataset_path: Path):\n",
    "    if sentiment == Sentiment.POS:\n",
    "        sentiment_value = 1\n",
    "    elif sentiment == Sentiment.NEG:\n",
    "        sentiment_value = 0\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "    files = []\n",
    "    path_to_data = dataset_path / sentiment\n",
    "    file_paths = path_to_data.glob(\"*.txt\")\n",
    "    for file_path in file_paths:\n",
    "        with open(file=file_path) as text_file:\n",
    "            files.append(text_file.read())\n",
    "\n",
    "    sentiment_list = [sentiment_value] * len(files)\n",
    "    \n",
    "    return files, sentiment_list \n",
    "\n",
    "def load_dataframe(sentiment: Sentiment, dataset_path: Path):\n",
    "    columns = [\"text\", \"sentiment_value\"]\n",
    "    df = pd.DataFrame(dict(zip(columns, _load_data(sentiment=sentiment, dataset_path=dataset_path))))\n",
    "    return df\n",
    "\n",
    "def load_dataset(dataset_path: Path):\n",
    "    dataset_df = pd.concat([load_dataframe(sentiment=sentiment, dataset_path=dataset_path) for sentiment in Sentiment])\n",
    "    return dataset_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e628559",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_full = load_dataset(dataset_path=train_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d3e9d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zentropa has much in common with The Third Man...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zentropa is the most original movie I've seen ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lars Von Trier is never backward in trying out...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*Contains spoilers due to me having to describ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That was the first thing that sprang to mind a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>There just isn't enough here. There a few funn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>Tainted look at kibbutz life&lt;br /&gt;&lt;br /&gt;This f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>I saw this movie, just now, not when it was re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>Any film which begins with a cowhand shagging ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>Yes AWA wrestling how can anyone forget about ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment_value\n",
       "0      Zentropa has much in common with The Third Man...                1\n",
       "1      Zentropa is the most original movie I've seen ...                1\n",
       "2      Lars Von Trier is never backward in trying out...                1\n",
       "3      *Contains spoilers due to me having to describ...                1\n",
       "4      That was the first thing that sprang to mind a...                1\n",
       "...                                                  ...              ...\n",
       "12495  There just isn't enough here. There a few funn...                0\n",
       "12496  Tainted look at kibbutz life<br /><br />This f...                0\n",
       "12497  I saw this movie, just now, not when it was re...                0\n",
       "12498  Any film which begins with a cowhand shagging ...                0\n",
       "12499  Yes AWA wrestling how can anyone forget about ...                0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72fc2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    df_train_full, test_size=0.2, random_state=42, stratify=df_train_full[\"sentiment_value\"]\n",
    ")\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_ds = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, max_length=256)\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "val_ds = val_ds.map(tokenize, batched=True)\n",
    "\n",
    "# Trainer expects label column named \"labels\"\n",
    "train_ds = train_ds.rename_column(\"sentiment_value\", \"labels\")\n",
    "val_ds = val_ds.rename_column(\"sentiment_value\", \"labels\")\n",
    "\n",
    "cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "train_ds.set_format(type=\"torch\", columns=cols)\n",
    "val_ds.set_format(type=\"torch\", columns=cols)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "    }\n",
    "\n",
    "# transformers==5 uses `eval_strategy` (not `evaluation_strategy`)\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"outputs/sentiment_distilbert\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2,\n",
    "    seed=42,\n",
    "    data_seed=42,\n",
    "    remove_unused_columns=True,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    use_cpu=False,\n",
    " )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics,\n",
    " )\n",
    "\n",
    "# trainer.train()\n",
    "# trainer.evaluate()\n",
    "# trainer.save_model(\"outputs/sentiment_distilbert/best\")\n",
    "# tokenizer.save_pretrained(\"outputs/sentiment_distilbert/best\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
