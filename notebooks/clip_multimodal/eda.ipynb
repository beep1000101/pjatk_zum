{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIP (multimodal) â€“ evaluation notebook\n",
    "# Goal: evaluate a pretrained CLIP model on CIFAR-10 from our cache.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for p in [cur, *cur.parents]:\n",
    "        if (p / \"data_ingestion\").exists() and (p / \"utils\").exists():\n",
    "            return p\n",
    "    return cur\n",
    "\n",
    "\n",
    "ROOT = find_repo_root(Path())\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "from utils.paths import CACHE_PATH  # noqa: E402\n",
    "\n",
    "CACHE = CACHE_PATH\n",
    "RAW_DIR = CACHE / \"clip_multimodal\" / \"raw\" / \"cifar-10-batches-py\"\n",
    "OUTPUTS_DIR = ROOT / \"outputs\" / \"clip_multimodal\"\n",
    "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b45733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure dataset is present in cache (runs ingestion if needed)\n",
    "if not RAW_DIR.exists():\n",
    "    print(\"CIFAR-10 not found in cache; running ingestion...\")\n",
    "    # This populates: .cache/clip_multimodal/raw/cifar-10-batches-py\n",
    "    # and writes: .cache/clip_multimodal/label_texts.json\n",
    "    !python data_ingestion/clip_multimodal/run.py\n",
    "\n",
    "assert RAW_DIR.exists(), f\"Missing: {RAW_DIR}\"\n",
    "\n",
    "label_texts_path = CACHE / \"clip_multimodal\" / \"label_texts.json\"\n",
    "if label_texts_path.exists():\n",
    "    labels = json.loads(label_texts_path.read_text(encoding=\"utf-8\"))\n",
    "else:\n",
    "    # Fallback (CIFAR-10 class names)\n",
    "    labels = [\n",
    "        \"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\n",
    "        \"dog\",\"frog\",\"horse\",\"ship\",\"truck\",\n",
    "    ]\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e5c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 test split (python batches)\n",
    "test_batch_path = RAW_DIR / \"test_batch\"\n",
    "with open(test_batch_path, \"rb\") as f:\n",
    "    batch = pickle.load(f, encoding=\"bytes\")\n",
    "\n",
    "# images: (N, 32, 32, 3), uint8\n",
    "images = batch[b\"data\"].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "y_true = np.array(batch[b\"labels\"], dtype=np.int64)\n",
    "\n",
    "len(images), images.shape, y_true[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained CLIP and precompute text features\n",
    "model_id = \"openai/clip-vit-base-patch32\"\n",
    "model = CLIPModel.from_pretrained(model_id).to(device)\n",
    "processor = CLIPProcessor.from_pretrained(model_id)\n",
    "\n",
    "texts = [f\"a photo of a {lbl}\" for lbl in labels]\n",
    "text_inputs = processor(text=texts, return_tensors=\"pt\", padding=True).to(device)\n",
    "text_features = model.get_text_features(**text_inputs)\n",
    "text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "model_id, text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ecce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate top-1 accuracy on a subset (prompt retrieval)\n",
    "N = 1000  # increase to 10_000 for full CIFAR-10 test\n",
    "batch_size = 64\n",
    "\n",
    "n = min(N, len(images))\n",
    "preds: list[int] = []\n",
    "\n",
    "for start in range(0, n, batch_size):\n",
    "    end = min(start + batch_size, n)\n",
    "    batch_imgs = [Image.fromarray(images[i]) for i in range(start, end)]\n",
    "    img_inputs = processor(images=batch_imgs, return_tensors=\"pt\").to(device)\n",
    "    img_features = model.get_image_features(**img_inputs)\n",
    "    img_features = img_features / img_features.norm(dim=-1, keepdim=True)\n",
    "    logits = img_features @ text_features.T\n",
    "    preds.extend(torch.argmax(logits, dim=-1).detach().cpu().tolist())\n",
    "\n",
    "y_pred = np.array(preds, dtype=np.int64)\n",
    "acc = float((y_pred == y_true[:n]).mean())\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3fdd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics + a small prediction report\n",
    "metrics = {\n",
    "    \"pipeline\": \"clip_multimodal\",\n",
    "    \"model_id\": model_id,\n",
    "    \"num_eval\": int(n),\n",
    "    \"top1_accuracy\": acc,\n",
    "    \"labels\": labels,\n",
    "    \"prompt_template\": \"a photo of a {label}\",\n",
    "}\n",
    "\n",
    "(OUTPUTS_DIR / \"evaluation\").mkdir(parents=True, exist_ok=True)\n",
    "metrics_path = OUTPUTS_DIR / \"evaluation\" / \"metrics.json\"\n",
    "metrics_path.write_text(json.dumps(metrics, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "rows = []\n",
    "for i in range(min(50, n)):\n",
    "    rows.append({\n",
    "        \"idx\": i,\n",
    "        \"true_id\": int(y_true[i]),\n",
    "        \"true_label\": labels[int(y_true[i])],\n",
    "        \"pred_id\": int(y_pred[i]),\n",
    "        \"pred_label\": labels[int(y_pred[i])],\n",
    "    })\n",
    "\n",
    "report_df = pd.DataFrame(rows)\n",
    "report_csv = OUTPUTS_DIR / \"evaluation\" / \"sample_predictions.csv\"\n",
    "report_df.to_csv(report_csv, index=False)\n",
    "\n",
    "metrics_path, report_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b080bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Zip outputs for sharing (e.g., Colab -> download)\n",
    "!zip -r clip_multimodal_outputs.zip outputs/clip_multimodal"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
